【就安装Attention这个论文的格式写】



图一是我们所提出RT方法结构一层的示意图

输入为 $X = [x_1,x_2,...x_t,...x_T]$

其中$ x_t $表示在帧$ t $处的嘈杂语音的幅度谱，$ T $ 表示语音段的帧总数

具体来说，每一层中包含三个网络：LocalRNN、MultiheadAttention、FeedForward:



较低级别的是localRNN，它们顺序处理本地窗口中的位置

$h_1,h-2，...，h_N = LocalRNN(x_1，x_2,...,x_N)$

s

中间层是捕获长期依赖关系的多头注意力网络
$$
\begin{aligned}u_t &= MultiHeadAttention(h_1,h_2,...,h_t)\\&=Concatenation(head_1(h_t),head_2(h_t),...,head_k(h_t))W^o\end{aligned}
$$
上层是进行非线性特征变换的位置前馈网络
$$
FeedForward(m_t)=max(0,u_tW_1+b_1)W_2+b_2
$$
这三个网络通过残差和层规范化操作连接。带虚线的圆圈是输入序列的填充

/home/ubuntu/yww/IRMLSTM/config/train/2020_04_08_zrt_musan_32.json5







---

#### 整体安排

1. introduction

   > 语音增强的意义。
   >
   > 

2. model

   > 我们的整体流程图如图1所示。输入是[x1,...xt]，表示的是
   >
   > 先经过一个localRNN 隐式的

3. experiment

4. conclusion

5. reference