#### Abstract

- [ ] 原来用的是什么？ 

  循环神经网络，

- [ ] 有什么缺点？

  不可以并行计算；

- [ ] 本文针对这个缺点做了什么改进？

  提出了RT，既可以并行计算，又不需要位置嵌入。

- [ ] 实验效果如何？

  比transformer 和 rnns 效果好，

---

正式版：

Recurrent neural networks (RNNs), such as LSTMs, GRUs. were important neural network architectures in speech enhancement, due to their powerful sequence learning. 

However, it severely suffers from a issues: unable to parallelize the sequential computation procedure.

Therefore, many non-recurrent sequence models that are built on convolution and attention operations have been proposed recently. 

Notably, models with multi-head attention such as Transformer have demonstrated extreme effectiveness on many natural language processing (NLP) tasks.

But they are non-trivial to apply to speech enhancement due to heavily rely on position embeddings  that require a considerable amount of design efforts.

In this paper, we propose the R-Transformer which enjoys the advantages of both RNNs and the multi-head attention mechanism while avoids their respective drawback.

Experiments show that, as compared with Transformer and the RNNs baseline, the proposed attention approach can consistently achieve better performance in terms of speech quality (PESQ) and intelligibility (STOI). 

More promisingly, the proposed approach has better generalization ability to unseen noise conditions. 

---

Recurrent neural networks (RNNs), such as LSTMs, GRUs, were popular neural network architectures in speech enhancement, due to their powerful sequence learning. 
However, it severely suffers from an issue: unable to parallelize the sequential computation procedure.
Therefore, many non-recurrent sequence models that are built on convolution and attention operations have been proposed recently. 
Notably, models with multi-head attention such as Transformer have demonstrated extreme effectiveness on many natural language processing (NLP) tasks.
However, they are non-trivial to apply to speech enhancement due to heavily rely on position embeddings that require a considerable amount of design efforts.
In this paper, we propose the R-Transformer, which enjoys the advantages of both RNNs and the multi-head attention mechanism while avoids their respective drawback.
Experiments show that, as compared with the Transformer and the RNNs baseline, the proposed attention approach can consistently achieve better performance in terms of speech quality (PESQ) and intelligibility (STOI). 
More promisingly, the proposed approach has better generalization ability to unseen noise conditions. 



---

Transformer neural networks (TNN) demonstrated state-of art performance on many natural language processing (NLP) tasks, replacing recurrent neural networks (RNNs), such as LSTMs or GRUs. However, TNNs did not perform well in speech enhancement, whose contextual nature is different than NLP tasks, like machine translation. Self-attention is a core building block of the Transformer, which not only enables parallelization of sequence computation, but also provides the constant path length between symbols that is essential to learning long-range dependencies. In this paper, we propose a Transformer with Gaussian-weighted self-attention (T-GSA), whose attention weights are attenuated according to the distance between target and context symbols. The experimental results show that the proposed T-GSA has significantly improved speech-enhancement performance, compared to the Transformer and RNNs. 

但是，它严重受到一个问题的困扰：无法并行化顺序计算过程。

在本文中，我们提出了一种R-Transformer，它既具有RNN和多头注意机制的优点，又避免了它们各自的缺点。
所提出的模型可以有效地捕获序列中的局部结构和全局长期依存关系，而无需使用位置嵌入。

实验表明，与native Transformer和LSTM基线相比，所提出的方法可以在语音质量（PESQ）和智能性（STOI）方面始终获得更好的性能。

更有希望的是，基于注意力的方法对看不见的噪声情况具有更好的概括能力

---

自我注意是一种基于成对相似性通过将向量彼此关联来对向量序列进行编码的方法。【】
这些模型最近显示了对离散序列进行建模的有希望的结果，但是由于计算和建模问题，它们在应用声学建模方面并非易事。
在本文中，我们将自我注意应用于声学建模，并提出了一些缓解这些问题的改进措施：首先，自我注意记忆的序列长度呈二次方增长，这通过下采样技术来解决。
其次，我们发现将位置信息合并到模型中的先前方法是不合适的，并为此探索了其他表示形式和混合模型。
第三，为了强调声信号中局部上下文的重要性，我们提出了一种高斯偏置方法，该方法允许在上下文范围内进行显式控制。
实验发现，我们的模型基于具有网络内网络连接的LSTM逼近强大的基线，同时计算速度更快。
除了速度，我们发现可解释性是自我注意声学模型的优势，并证明自我注意头学习了一种语言上合理的分工。1

---

长期以来，递归神经网络一直是序列建模的主要选择。【RT】
但是，它严重受到两个问题的困扰：无法捕获非常长期的依赖关系并且无法并行化顺序计算过程。
因此，近来提出了许多基于卷积和注意力运算的非递归序列模型。
值得注意的是，诸如Transformer之类的具有多头注意力的模型在捕获各种序列建模任务中的长期依存关系方面已显示出极高的效率。
尽管取得了成功，但这些模型仍缺少按顺序建模局部结构所需的组件，并且严重依赖效果有限且需要大量设计工作的位置嵌入。
在本文中，我们提出了一种R-Transformer，它既具有RNN和多头注意机制的优点，又避免了它们各自的缺点。
所提出的模型可以有效地捕获序列中的局部结构和全局长期依存关系，而无需使用位置嵌入。
通过对来自广泛领域的数据进行广泛的实验，我们对R-Transformer进行了评估，实证结果表明，R-Transformer在大多数任务中的性能远远优于最新方法。
我们已经在https://github.com/DSE-MSU/R-transformer上公开提供了该代码。

---

在日常聆听环境中，背景噪声，房间混响和干扰扬声器总是会使语音失真。
随着深度学习方法的发展，单声道多说话者语音分离已取得很大进展。
尽管如此，该领域的大多数研究都集中在实验室环境的简单问题设置上，没有考虑背景噪声和房间混响。
在本文中，我们提出了一个基于conv-TasNet的两阶段模型来分别处理噪声和干扰说话者的显着影响，其中使用深度扩张的时间卷积网络（TCN）依次进行增强和分离。
此外，我们开发了一个新的目标函数，称为最佳尺度不变信噪比（OSI-SNR），在任何情况下均优于原始SI-SNR。
通过与OSI-SNR一起训练两阶段模型，我们的算法大大优于一阶段分离基线

---

本文提出了一种基于注意力的神经网络方法进行单通道语音增强。
我们的工作是受关注模型在序列到序列学习中最近成功的启发。
在语音增强中使用注意力机制是很直观的，因为人们能够以“高度关注”关注音频流中的重要语音成分，同时感知“低关注度”中不重要的区域（例如，噪声或干扰），因此随时间调整焦点。
具体来说，以噪声频谱为例，我们的模型由基于LSTM的编码器，注意力机制和语音生成器组成，从而增强了频谱。
实验表明，与OM-LSA和LSTM基线相比，所提出的注意力方法可以在语音质量（PESQ）和智能性（STOI）方面始终获得更好的性能。
更有希望的是，基于注意力的方法对看不见的噪声情况具有更好的概括能力

---

本文研究了训练RNN（递归神经网络）的几个方面，这些方面会影响实时单通道语音增强的增强语音的主观和主观质量。
具体而言，我们专注于RNN，该RNN可在单帧输入，单帧输出的基础上增强短时语音频谱，这是大多数经典信号处理方法所采用的框架。
我们提出了两个新颖的基于均方误差的学习目标，它们可以分别控制语音失真和降噪的重要性。
拟议的损失函数通过广泛接受的客观质量和清晰度度量进行评估，并与其他竞争性在线方法进行比较。
另外，我们研究了特征归一化和变化的批处理序列长度对增强语音的客观质量的影响。
最后，我们对所提出的方法和最新的基于RNN的实时方法给出了主观评价。

---

变压器神经网络（TNN）在许多自然语言处理（NLP）任务上表现出了一流的性能，替代了递归神经网络（RNN），例如LSTM或GRU。
但是，TNN在语音增强方面表现不佳，其上下文本质与机器翻译等NLP任务不同。
自我注意是Transformer的核心构建模块，它不仅可以实现序列计算的并行化，而且可以提供符号之间的恒定路径长度，这对于学习远程依赖关系必不可少。
在本文中，我们提出了一种具有高斯加权自注意力（T-GSA）的变压器，其注意力权重根据目标和上下文符号之间的距离而衰减。
实验结果表明，与Transformer和RNN相比，拟议的T-GSA大大提高了语音增强性能

---

This paper proposes [ an attention-based neural network ] approach for single channel speech enhancement.

Our work is inspired by the recent success of attention models in sequence-sequence learning.

It is intuitive to use attention mechanism in speech enhancement as humans are able to focus on the important speech components in an audio stream with “high attention” while perceiving the unimportant region (e.g., noise or interference) in “low attention”, and thus adjust the focal point over time.

Specifically, taking noisy spectrum as in- put, our model is composed of an LSTM based encoder, an attention mechanism and a speech generator, resulting in enhanced spectrum.

Experiments show that, as compared with native Transformer and the LSTM baseline, the proposed attention approach can consistently achieve better performance in terms of speech quality (PESQ) and intelligibility (STOI). 

More promisingly, the attention-based approach has better generalization ability to unseen noise conditions.

#### Introduction

- [ ] 语音增强是什么？

  语音增强是一种试图从噪声中分离出语音的技术，目的是提高语音的质量和可懂度。

  语音增强旨在提高语音质量和清晰度，已经在学术界和行业中进行了广泛的研究。

  由于音频本质上是顺序的，因此尊重时间动态的递归神经网络（RNN）已成为一种强大的工具，特别是用于语音[1]和音乐[2]的建模。

- [ ] 近年来的主要方法？

  > 传统的方式
  >
  > dnn 使用数据驱动，
  >
  > cnn   比 dnn 好的地方是
  >
  > rnn   比cnn好的地方是

- [ ] 方法的缺点 或者说是 历史演变？

  > rnn 很适合，但是有缺点，
  >
  > 作为 代替品， 多头 在其他领域很适合，但是在语音领域不适合[ ] ，
  >
  > 本质上，是因为 transformer 依赖 位置嵌入

- [ ] 本文改进了什么？

  > rt 

**一个小时写好 introduction**

语音增强

TNN 已经证实在很多NLP任务上有很好的表现，作为循环网络的替代品。







当前的变压器网络没有在声音信号处理方面显示出改进，例如语音增强或语音去噪。
受益于许多NLP任务的固定路径长度属性与声学信号的物理特性不兼容，而声学信号的物理特性往往与更接近的组件更相关。
因此，需要位置编码以根据声信号特性来惩罚注意力权重，使得对更远的符号的注意力减少。
在本文中，我们提出了一种具有高斯加权自注意力（T-GSA）的变压器，其注意力权重根据相关符号之间的距离而衰减。
衰减由高斯方差确定，可以在训练过程中获知。
我们的评估结果表明，提出的T-GSA与现有的Transformer架构以及基于LSTM架构的最佳最佳递归模型相比都有显着改进。



---

语音增强是一种试图从噪声中分离出语音的技术，目的是提高语音的质量和可懂度。

Speech enhancement is a technique that attempts to separate speech from noise in order to improve speech quality and intelligibility.

It is a fundamental task with a wide range of applications, such as mobile telecommunication, hearing aids and automatic speech recognition, etc.

In these applications, the hearing experience or speech recognition performance will be degraded drastically when noise exists.  

In this paper, we study the single channel speech enhancement problem in which spatial information is unavailable, making the problem more challenging. 

---

Over the past several decades, Deep neural networks have shown great success in speech enhancement [1, 2, 3, 4, 5, 6] and performed better than the 

popular model-based statistical approaches, such as MMSE 

STSA [7] or OM-LSA [8, 9]. 



---

Speech enhancement, aiming to improve speech quality and intelligibility, has been widely investigated for many years in both academia and industry [1].                什么是语音增强

This technique is desired in many applications, e.g., mobile telecommunication, hearing aids and automatic speech recognition, etc.                                                          语音增强的应用

In these applications, the hearing experience or speech recognition performance will be degraded drastically when noise exists.                                                 

In this paper, we study the single channel speech enhancement problem in which spatial information is unavailable, making the problem more challenging.          本文中，我们研究了什么问题

---

Over the past several decades, a large variety of algorithms have been proposed.   过去很多算法被提出来

In general, these algorithms can be classified into two categories, namely statistical-based approaches and data-driven approaches. 

Statistical-based techniques include spectral subtraction [2], Wiener filtering [3], the minimum mean-square error log-spectral method [4], etc. 

Typical data-driven approaches include non-negative matrix factorization (NMF) [5] and neural network (N- N). 

Recently, with the development of deep learning (DL), deep neural network (DNN) have become a popular method.

---

DNN-based speech enhancement can be regarded as a regression or prediction task. 

Given a set of manually-prepared clean-noisy speech pairs, a neural network learns to transform noisy magnitude spectra to their clean equivalents [6, 7] or corresponding masks such as ideal binary mask (IBM) [8] and ideal ratio mask (IRM) [9]. 

Various DNN structures have been explored, such as deep autoencoder [10], convolutional neural network (CNN) [11], long short term memory (LSTM) network [12] and their combinations [13]. 

Popular machine learning strategies have also been employed, including multi-task learning [14], progressive learning [15] and reinforce- ment learning [16]. 

Several studies combine the spectral and phase information when the algorithm re-synthesizes the predicted features back into time-domain waveforms [17]. 

As another option of input, raw waveforms can be directly fed into a neural network as well. In this way, CNN [18], generative adversarial network (GAN) [19] and the popular audio generation model, WaveNet [20], have been studied. 

In the above DNN-based approaches, the loss function of most neural networks is mean-square error (MSE). Recently, perceptual evaluation criteria, e.g. PESQ, has been used as the optimization objective

---

In this paper, we explore the attention-based neural network structures for improving the performance of speech enhancement. 

Our work is inspired by the recent success of attention models in various sequence-to-sequence learning tasks, including machine trans- lation [22], speech recognition [23] and keyword spotting [24, 25]. 

It is intuitive to use attention mechanism in speech enhancement: humans are able to focus on a certain region of an audio stream with “high attention” (e.g., the target speech) while perceiving the surrounding audio (e.g., noise or interference) in “low attention”, and then adjust the focal point over time. 

Specifically, we adopt attention mechanism on LSTM-RNN models which have shown superior speech enhancement performances by modeling important sequential information [12]. 

While the RNN model learns weights of past input features implicitly when predicting enhanced frame, the attention mechanism calculates correlations between past frames and the current frame to be enhanced and give weights to past frames explicitly. 

Experiments show that, as compared with the LSTM baseline, the proposed attention approach can consistently achieve better performance in terms of speech quality (PESQ) and intelligibility (STOI). 

More promisingly, the attention-based approach has better generalization ability to unseen noise conditions.

#### Model

- [ ] 整体模型结构图
- [ ] 分层介绍每个结构
  - [ ] 针对输入 输出的顺序运算
  - [ ] 带入具体的事例

In this section, we introduce the architecture design of R-Transformer. 

To generate a target sequence in parallel, we design a novel feed-forward structure.

The overall model architecture of R-Transformer is shown in Figure 1.

The input $X = [x_1,x_2,...x_t,...x_T]$, where $x_t$ represents the magnitude spectrum of noisy speech at frame $t$ and $T$ represents the total number of frames of a speech segment. 

Specifically, our system contains of a stack of identical layers. Each layer has 3 components: local recurrent neural networks, multi-head attention in Transformer, 1D convolution. 



每一层之间都使用 残差加归一化。

the LocalRNN takes an input speech feature $x$ and outputs a sequence of hidden representations $h$ that incorporate information of local regions

$h_1,h_2,\cdots,h_N = LocalRNN(x_1,x_2,\cdots,x_N)$

In our work, we adopt LSTM as the encoder that has strong sequential modeling ability leading to superior performances in speech enhancement [12]. 

Then the multi head attention mechanism takes the $h$ as input and forms new representations $u_t$ calculated as:

$u_t = MultiHeadAttention(h)$

Finally, the $x'$ is the output of the feedforward which takes the representations $u_t$ as inputs:

$x' = FeedForward(u_t)$ 

We detail the Local RNN , the multi attention mechanism and the feedforward in the following subsection.



**Local RNN** 

Speech inherently exhibits strong local structures, so it is desirable and necessary to design components to model such locality. In this paper, we take the advantage of RNNs to achieve this. Unlike previous works where RNNs are often applied to the whole sequence, we instead reorganize the original long sequence into many short sequences which only contain local information and are processed by a shared RNN independently and identically. In particular, we construct a local window of size *M* for each target position such that the local window includes *M* consecutive positions and ends at the target position.  Thus, positions in each local window form a local short sequence, from which the shared RNN will learn a latent representation. In this way, the local structure information of each local region of the sequence is explicitly 

incorporated in the learned latent representations. We refer to the shared RNN as LocalRNN. Comparing to original RNN operation, LocalRNN only focuses on local short-term dependencies without considering any long-term dependencies. 

Concretely, given the positions $x_{t-M-1}, x_{t-M-2},· · ·, x_t$ of a local short sequence of length $M$, the LocalRNN processes them sequentially and outputs $M$ hidden states, the last of which is used as the representation of the local short sequences: 

To enable the model to process the sequence in an auto-regressive manner and take care that no future information is available when processing one position, we pad the input sequence by ($M-1$) positions before the start of a sequence. Thus, from sequence perspective, the LocalRNN takes an input sequence and outputs a sequence of hidden representations that incorporate information of local regions:



The localRNN is analogous to 1-D Convolution Neural Networks where each local window is processed by convolution operations. However, the convolution operation completely ignores the sequential information of positions within the local window. Although the position embeddings have been proposed to mitigate this problem, a major defificiency of this approach is that the effectiveness of the position embedding could be limited; thus it requires considerable amount of extra efforts (Gehring et al., 2017). On the other hand, the LocalRNN is able to fully capture the sequential information within each window. In addition, the one-by-one sliding operation also naturally incorporates the global sequential information.



Overall, the LocalRNN is applied to a short sequence within a local window of fifixed size, where no long-term dependency is needed to capture. In addition, the computation procedures for processing the short sequences are independent of each other. Therefore, it is very straightforward for the parallel implementation (e.g., using GPUs), which can greatly improve the computation effificiency.

图2显示了原始RNN和LocalRNN操作之间的区别。
具体来说，给定长度为M的局部短序列的位置xt M 1，xt M 2，···，xt，LocalRNN顺序处理它们并输出M个隐藏状态，最后一个状态用作局部状态的表示
短序列：





Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, Anhui University, Hefei 230601, China 



**Multi-Attention**

Recent works have shown that the multi-head attention mechanism is extremely effective to learn the long-term dependencies, as it allows a direct connection between every pair of positions. More specififically, in the multi-head attention mechanism, each position will attend to all the positions in the past and obtains a set of attention scores that are used to refifine its representation. Mathematically, given current representations $h_1,h-2，...，h_N $ the refined new representations $u_t$ are calculated as:





**FeedForward**    找到 fastspeech

Different from the 2-layer dense network in Transformer, we use a 2-layer 1D convolutional network with ReLU activation. 

The motivation is that the adjacent hidden states are more closely related in the character/phoneme and mel-spectrogram.

We evaluate the effectiveness of the 1D convolutional network in the experimental section. 



Following Transformer [25], residual connections, layer normalization, and dropout are added after the self-attention network and 1D convolutional network respectively. 

总的公式：

With all the aforementioned model components, we can now give a formal description of the overall 

architecture of an *N*-layer R-Transformer. For the *i* *th* layer (*i* *∈ {*1*,* 2*,* *· · ·* *N**}*):



建议的R-Transformer由相同层的堆栈组成。
每个层具有3个按层次结构组织的组件，并且该层结构的体系结构如图1所示。如图所示，较低层是设计用于对序列中的局部结构进行建模的局部递归神经网络。
中层是多头关注点，能够捕获全球长期依赖关系；
上层是进行非线性特征变换的位置前馈网络。
接下来，我们详细描述每个级别。



local rnn

multihead attention

#### Experiment



