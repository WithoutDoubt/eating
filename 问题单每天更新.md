1. IRM 中的model的输入是什么？是什么形状的？

   > 一条语音是 [ T , D] 即 [10, 257]
   >
   > 多条语音合在一起就是 [T, Batch_size ,  D] 即 [10 , 32, 257]
   >
   > ​		合一起的时候需要pad 一下，补齐 T,  然后就可以整体合并了
   >
   > 因为pytorch 中是 Batch first 所以是 [B, T, D] 即 [32, 10, 257]

2. Paddle 中 seq2seq 的输入是什么样子的？

   > 生成器 创建 一个 大的数据
   >
   > 使用 prepare_input 来手动获取 batch 个

3. model 中每一层是变成什么样的？

4. model 中 lstm 是怎么样计算 (B, T, D) 的？

5. mask 部分是怎么操作的？

6. python 中生成器是什么？

   > 就是用于创建【迭代器】的简单而强大的工具。
   >
   > 对生成器调用next( ) ，它会从上次离开位置恢复执行。
   >
   > 也就是说，for 循环 会在上次的地方恢复然后执行下一个

7. python 中 访问 什么用的到 enumerate( ) ？

   > 序列用的是 enumerate
   >
   > 字典是用item

8. Python中循环的技巧有哪些？

   >  items( ) 来取 字典
   >
   > enumerate( ) 来取序列
   >
   > 多个序列使用 zip( )

9. 怎么把 mag 和 phase 合在一起？

   > mag * phase

10. tensorflow 的 dataloader 怎么写的？

11. python 中的 成员 可以有其他 对象？

12. `librosa.magphase` 返回的 shape 是什么样的？

    （d，t）比如 （257，10）

13. IRM 的公式是什么？

14. LPS 的公式是什么？

15. pesq是测试什么的？

16. stoi是测试什么的？

17. 多目标是怎么实现的？

18. stoi + pesq 的 loss 是怎么实现的？

19. 怎么实现多GPU训练？

    有好几种，有一种可以 每一层为一个 GPU

20. 